{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize your data\n",
    "\n",
    "<img src=\"./media/data.gif\" width=\"480\" height=\"360\">\n",
    "\n",
    "Visualize your action based on the reconstructed simulation scene. \n",
    "\n",
    "The main simulation is replaying the action.\n",
    "\n",
    "The overlayed images on the top right and bottom right are from the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongeun/.pyenv/versions/3.10.2/envs/lerobot/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Generating train split: 221 examples [00:00, 3549.16 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from lerobot.common.datasets.lerobot_dataset import LeRobotDataset, LeRobotDatasetMetadata\n",
    "import numpy as np\n",
    "from lerobot.common.datasets.utils import write_json, serialize_dict\n",
    "\n",
    "dataset = LeRobotDataset('omy_pnp', root='./demo_data') # if youu want to use the example data provided, root = './demo_data_exmple' instead!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class EpisodeSampler(torch.utils.data.Sampler):\n",
    "    \"\"\"\n",
    "    Sampler for a single episode\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset: LeRobotDataset, episode_index: int):\n",
    "        from_idx = dataset.episode_data_index[\"from\"][episode_index].item()\n",
    "        to_idx = dataset.episode_data_index[\"to\"][episode_index].item()\n",
    "        self.frame_ids = range(from_idx, to_idx)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.frame_ids)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.frame_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select an episode index that you want to visualize\n",
    "episode_index = 0\n",
    "\n",
    "episode_sampler = EpisodeSampler(dataset, episode_index)\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    num_workers=1,\n",
    "    batch_size=1,\n",
    "    sampler=episode_sampler,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize your Dataset on Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jeongeun/Dropbox/code/vla_prj/lerobot_tutorial/asset/example_scene_y.xml\n",
      "['agentview', 'topview', 'sideview', 'egocentric']\n",
      "name:[Tabletop] dt:[0.002] HZ:[500]\n",
      "n_qpos:[24] n_qvel:[22] n_qacc:[22] n_ctrl:[10]\n",
      "\n",
      "n_body:[21]\n",
      " [0/21] [world] mass:[0.00]kg\n",
      " [1/21] [front_object_table] mass:[1.00]kg\n",
      " [2/21] [camera] mass:[0.00]kg\n",
      " [3/21] [camera2] mass:[0.00]kg\n",
      " [4/21] [camera3] mass:[0.00]kg\n",
      " [5/21] [link1] mass:[2.06]kg\n",
      " [6/21] [link2] mass:[3.68]kg\n",
      " [7/21] [link3] mass:[2.39]kg\n",
      " [8/21] [link4] mass:[1.40]kg\n",
      " [9/21] [link5] mass:[1.40]kg\n",
      " [10/21] [link6] mass:[0.65]kg\n",
      " [11/21] [camera_center] mass:[0.00]kg\n",
      " [12/21] [tcp_link] mass:[0.32]kg\n",
      " [13/21] [rh_p12_rn_r1] mass:[0.07]kg\n",
      " [14/21] [rh_p12_rn_r2] mass:[0.02]kg\n",
      " [15/21] [rh_p12_rn_l1] mass:[0.07]kg\n",
      " [16/21] [rh_p12_rn_l2] mass:[0.02]kg\n",
      " [17/21] [body_obj_mug_5] mass:[0.00]kg\n",
      " [18/21] [object_mug_5] mass:[0.08]kg\n",
      " [19/21] [body_obj_plate_11] mass:[0.00]kg\n",
      " [20/21] [object_plate_11] mass:[0.10]kg\n",
      "body_total_mass:[13.27]kg\n",
      "\n",
      "n_geom:[83]\n",
      "geom_names:['floor', None, 'front_object_table', None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]\n",
      "\n",
      "n_joint:[12]\n",
      " [0/12] [joint1] axis:[0. 0. 1.]\n",
      " [1/12] [joint2] axis:[0. 1. 0.]\n",
      " [2/12] [joint3] axis:[0. 1. 0.]\n",
      " [3/12] [joint4] axis:[0. 1. 0.]\n",
      " [4/12] [joint5] axis:[0. 0. 1.]\n",
      " [5/12] [joint6] axis:[0. 1. 0.]\n",
      " [6/12] [rh_r1] axis:[1. 0. 0.]\n",
      " [7/12] [rh_r2] axis:[-1.  0.  0.]\n",
      " [8/12] [rh_l1] axis:[-1.  0.  0.]\n",
      " [9/12] [rh_l2] axis:[1. 0. 0.]\n",
      " [10/12] [None] axis:[0. 0. 1.]\n",
      " [11/12] [None] axis:[0. 0. 1.]\n",
      "\n",
      "n_dof:[22] (=number of rows of Jacobian)\n",
      " [0/22] [None] attached joint:[joint1] body:[link1]\n",
      " [1/22] [None] attached joint:[joint2] body:[link2]\n",
      " [2/22] [None] attached joint:[joint3] body:[link3]\n",
      " [3/22] [None] attached joint:[joint4] body:[link4]\n",
      " [4/22] [None] attached joint:[joint5] body:[link5]\n",
      " [5/22] [None] attached joint:[joint6] body:[link6]\n",
      " [6/22] [None] attached joint:[rh_r1] body:[rh_p12_rn_r1]\n",
      " [7/22] [None] attached joint:[rh_r2] body:[rh_p12_rn_r2]\n",
      " [8/22] [None] attached joint:[rh_l1] body:[rh_p12_rn_l1]\n",
      " [9/22] [None] attached joint:[rh_l2] body:[rh_p12_rn_l2]\n",
      " [10/22] [None] attached joint:[None] body:[body_obj_mug_5]\n",
      " [11/22] [None] attached joint:[None] body:[body_obj_mug_5]\n",
      " [12/22] [None] attached joint:[None] body:[body_obj_mug_5]\n",
      " [13/22] [None] attached joint:[None] body:[body_obj_mug_5]\n",
      " [14/22] [None] attached joint:[None] body:[body_obj_mug_5]\n",
      " [15/22] [None] attached joint:[None] body:[body_obj_mug_5]\n",
      " [16/22] [None] attached joint:[None] body:[body_obj_plate_11]\n",
      " [17/22] [None] attached joint:[None] body:[body_obj_plate_11]\n",
      " [18/22] [None] attached joint:[None] body:[body_obj_plate_11]\n",
      " [19/22] [None] attached joint:[None] body:[body_obj_plate_11]\n",
      " [20/22] [None] attached joint:[None] body:[body_obj_plate_11]\n",
      " [21/22] [None] attached joint:[None] body:[body_obj_plate_11]\n",
      "\n",
      "Free joint information. n_free_joint:[2]\n",
      " [0/2] [None] body_name_attached:[body_obj_mug_5]\n",
      " [1/2] [None] body_name_attached:[body_obj_plate_11]\n",
      "\n",
      "Revolute joint information. n_rev_joint:[10]\n",
      " [0/10] [joint1] range:[-6.283]~[6.283]\n",
      " [1/10] [joint2] range:[-6.283]~[6.283]\n",
      " [2/10] [joint3] range:[-6.283]~[6.283]\n",
      " [3/10] [joint4] range:[-6.283]~[6.283]\n",
      " [4/10] [joint5] range:[-6.283]~[6.283]\n",
      " [5/10] [joint6] range:[-6.283]~[6.283]\n",
      " [6/10] [rh_r1] range:[0.000]~[1.100]\n",
      " [7/10] [rh_r2] range:[0.000]~[1.000]\n",
      " [8/10] [rh_l1] range:[0.000]~[1.100]\n",
      " [9/10] [rh_l2] range:[0.000]~[1.000]\n",
      "\n",
      "Prismatic joint information. n_pri_joint:[0]\n",
      "\n",
      "Control information. n_ctrl:[10]\n",
      " [0/10] [actuator_joint1] range:[-6.283]~[6.283] gear:[1.00] type:[JOINT]\n",
      " [1/10] [actuator_joint2] range:[-6.283]~[6.283] gear:[1.00] type:[JOINT]\n",
      " [2/10] [actuator_joint3] range:[-6.283]~[6.283] gear:[1.00] type:[JOINT]\n",
      " [3/10] [actuator_joint4] range:[-6.283]~[6.283] gear:[1.00] type:[JOINT]\n",
      " [4/10] [actuator_joint5] range:[-6.283]~[6.283] gear:[1.00] type:[JOINT]\n",
      " [5/10] [actuator_joint6] range:[-6.283]~[6.283] gear:[1.00] type:[JOINT]\n",
      " [6/10] [actuator_rh_r1] range:[0.000]~[1.100] gear:[1.00] type:[JOINT]\n",
      " [7/10] [actuator_rh_r2] range:[0.000]~[1.000] gear:[1.00] type:[JOINT]\n",
      " [8/10] [actuator_rh_l1] range:[0.000]~[1.100] gear:[1.00] type:[JOINT]\n",
      " [9/10] [actuator_rh_l2] range:[0.000]~[1.000] gear:[1.00] type:[JOINT]\n",
      "\n",
      "Camera information. n_cam:[4]\n",
      " [0/4] [agentview] fov:[60.0]\n",
      " [1/4] [topview] fov:[90.0]\n",
      " [2/4] [sideview] fov:[90.0]\n",
      " [3/4] [egocentric] fov:[90.0]\n",
      "\n",
      "n_sensor:[0]\n",
      "sensor_names:[]\n",
      "n_site:[6]\n",
      "site_names:['bottom_site_mug_5', 'top_site_mug_5', 'horizontal_radius_site_mug_5', 'bottom_site_plate_11', 'top_site_plate_11', 'horizontal_radius_site_plate_11']\n",
      "env:[Tabletop] reset\n",
      "env:[Tabletop] reset\n",
      "env:[Tabletop] initalize viewer\n",
      "DONE INITIALIZATION\n"
     ]
    }
   ],
   "source": [
    "from mujoco_env.y_env import SimpleEnv\n",
    "xml_path = './asset/example_scene_y.xml'\n",
    "PnPEnv = SimpleEnv(xml_path, action_type='joint_angle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE INITIALIZATION\n",
      "DONE INITIALIZATION\n"
     ]
    }
   ],
   "source": [
    "step = 0\n",
    "iter_dataloader = iter(dataloader)\n",
    "PnPEnv.reset()\n",
    "\n",
    "while PnPEnv.env.is_viewer_alive():\n",
    "    PnPEnv.step_env()\n",
    "    if PnPEnv.env.loop_every(HZ=20):\n",
    "        # Get the action from dataset\n",
    "        data = next(iter_dataloader)\n",
    "        if step == 0:\n",
    "            # Reset the object pose based on the dataset\n",
    "            PnPEnv.set_obj_pose(data['obj_init'][0,:3], data['obj_init'][0,3:])\n",
    "        # Get the action from dataset\n",
    "        action = data['action'].numpy()\n",
    "        obs = PnPEnv.step(action[0])\n",
    "\n",
    "        # Visualize the image from dataset to rgb_overlay\n",
    "        PnPEnv.rgb_agent = data['observation.image'][0].numpy()*255\n",
    "        PnPEnv.rgb_ego = data['observation.wrist_image'][0].numpy()*255\n",
    "        PnPEnv.rgb_agent = PnPEnv.rgb_agent.astype(np.uint8)\n",
    "        PnPEnv.rgb_ego = PnPEnv.rgb_ego.astype(np.uint8)\n",
    "        # 3 256 256 -> 256 256 3\n",
    "        PnPEnv.rgb_agent = np.transpose(PnPEnv.rgb_agent, (1,2,0))\n",
    "        PnPEnv.rgb_ego = np.transpose(PnPEnv.rgb_ego, (1,2,0))\n",
    "        PnPEnv.rgb_side = np.zeros((480, 640, 3), dtype=np.uint8)\n",
    "        PnPEnv.rgb_top = np.zeros((480, 640, 3), dtype=np.uint8)\n",
    "        PnPEnv.render()\n",
    "        step += 1\n",
    "\n",
    "        if step == len(episode_sampler):\n",
    "            # start from the beginning\n",
    "            iter_dataloader = iter(dataloader)\n",
    "            PnPEnv.reset()\n",
    "            step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "PnPEnv.env.close_viewer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Optional] Save Stats.json for other versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = dataset.meta.stats\n",
    "PATH = dataset.root / 'meta' / 'stats.json'\n",
    "stats = serialize_dict(stats)\n",
    "\n",
    "write_json(stats, PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lerobot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
