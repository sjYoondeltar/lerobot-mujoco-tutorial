{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect Demonstration from Keyboard\n",
    "\n",
    "Collect demonstration data for the given environment.\n",
    "The task is to pick a mug and place it on the plate. The environment recognizes the success if the mug is on the plate, gthe ripper opened, and the end-effector positioned above the mug.\n",
    "\n",
    "<img src=\"./media/teleop.gif\" width=\"480\" height=\"360\">\n",
    "\n",
    "Use WASD for the xy plane, RF for the z-axis, QE for tilt, and ARROWs for the rest of rthe otations. \n",
    "\n",
    "SPACEBAR will change your gripper's state, and Z key will reset your environment with discarding the current episode data.\n",
    "\n",
    "For overlayed images, \n",
    "- Top Right: Agent View \n",
    "- Bottom Right: Egocentric View\n",
    "- Top Left: Left Side View\n",
    "- Bottom Left: Top View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongeun/.pyenv/versions/3.10.2/envs/lerobot/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "from mujoco_env.y_env import SimpleEnv\n",
    "from lerobot.common.datasets.lerobot_dataset import LeRobotDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to randomize the object positions, set this to None\n",
    "# If you fix the seed, the object positions will be the same every time\n",
    "SEED = 0 \n",
    "# SEED = None <- Uncomment this line to randomize the object positions\n",
    "\n",
    "REPO_NAME = 'omy_pnp'\n",
    "NUM_DEMO = 1 # Number of demonstrations to collect\n",
    "ROOT = \"./demo_data\" # The root directory to save the demonstrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jeongeun/Dropbox/code/vla_prj/lerobot_tutorial/asset/example_scene_y.xml\n",
      "['agentview', 'topview', 'sideview', 'egocentric']\n",
      "name:[Tabletop] dt:[0.002] HZ:[500]\n",
      "n_qpos:[24] n_qvel:[22] n_qacc:[22] n_ctrl:[10]\n",
      "\n",
      "n_body:[21]\n",
      " [0/21] [world] mass:[0.00]kg\n",
      " [1/21] [front_object_table] mass:[1.00]kg\n",
      " [2/21] [camera] mass:[0.00]kg\n",
      " [3/21] [camera2] mass:[0.00]kg\n",
      " [4/21] [camera3] mass:[0.00]kg\n",
      " [5/21] [link1] mass:[2.06]kg\n",
      " [6/21] [link2] mass:[3.68]kg\n",
      " [7/21] [link3] mass:[2.39]kg\n",
      " [8/21] [link4] mass:[1.40]kg\n",
      " [9/21] [link5] mass:[1.40]kg\n",
      " [10/21] [link6] mass:[0.65]kg\n",
      " [11/21] [camera_center] mass:[0.00]kg\n",
      " [12/21] [tcp_link] mass:[0.32]kg\n",
      " [13/21] [rh_p12_rn_r1] mass:[0.07]kg\n",
      " [14/21] [rh_p12_rn_r2] mass:[0.02]kg\n",
      " [15/21] [rh_p12_rn_l1] mass:[0.07]kg\n",
      " [16/21] [rh_p12_rn_l2] mass:[0.02]kg\n",
      " [17/21] [body_obj_mug_5] mass:[0.00]kg\n",
      " [18/21] [object_mug_5] mass:[0.08]kg\n",
      " [19/21] [body_obj_plate_11] mass:[0.00]kg\n",
      " [20/21] [object_plate_11] mass:[0.10]kg\n",
      "body_total_mass:[13.27]kg\n",
      "\n",
      "n_geom:[83]\n",
      "geom_names:['floor', None, 'front_object_table', None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]\n",
      "\n",
      "n_joint:[12]\n",
      " [0/12] [joint1] axis:[0. 0. 1.]\n",
      " [1/12] [joint2] axis:[0. 1. 0.]\n",
      " [2/12] [joint3] axis:[0. 1. 0.]\n",
      " [3/12] [joint4] axis:[0. 1. 0.]\n",
      " [4/12] [joint5] axis:[0. 0. 1.]\n",
      " [5/12] [joint6] axis:[0. 1. 0.]\n",
      " [6/12] [rh_r1] axis:[1. 0. 0.]\n",
      " [7/12] [rh_r2] axis:[-1.  0.  0.]\n",
      " [8/12] [rh_l1] axis:[-1.  0.  0.]\n",
      " [9/12] [rh_l2] axis:[1. 0. 0.]\n",
      " [10/12] [None] axis:[0. 0. 1.]\n",
      " [11/12] [None] axis:[0. 0. 1.]\n",
      "\n",
      "n_dof:[22] (=number of rows of Jacobian)\n",
      " [0/22] [None] attached joint:[joint1] body:[link1]\n",
      " [1/22] [None] attached joint:[joint2] body:[link2]\n",
      " [2/22] [None] attached joint:[joint3] body:[link3]\n",
      " [3/22] [None] attached joint:[joint4] body:[link4]\n",
      " [4/22] [None] attached joint:[joint5] body:[link5]\n",
      " [5/22] [None] attached joint:[joint6] body:[link6]\n",
      " [6/22] [None] attached joint:[rh_r1] body:[rh_p12_rn_r1]\n",
      " [7/22] [None] attached joint:[rh_r2] body:[rh_p12_rn_r2]\n",
      " [8/22] [None] attached joint:[rh_l1] body:[rh_p12_rn_l1]\n",
      " [9/22] [None] attached joint:[rh_l2] body:[rh_p12_rn_l2]\n",
      " [10/22] [None] attached joint:[None] body:[body_obj_mug_5]\n",
      " [11/22] [None] attached joint:[None] body:[body_obj_mug_5]\n",
      " [12/22] [None] attached joint:[None] body:[body_obj_mug_5]\n",
      " [13/22] [None] attached joint:[None] body:[body_obj_mug_5]\n",
      " [14/22] [None] attached joint:[None] body:[body_obj_mug_5]\n",
      " [15/22] [None] attached joint:[None] body:[body_obj_mug_5]\n",
      " [16/22] [None] attached joint:[None] body:[body_obj_plate_11]\n",
      " [17/22] [None] attached joint:[None] body:[body_obj_plate_11]\n",
      " [18/22] [None] attached joint:[None] body:[body_obj_plate_11]\n",
      " [19/22] [None] attached joint:[None] body:[body_obj_plate_11]\n",
      " [20/22] [None] attached joint:[None] body:[body_obj_plate_11]\n",
      " [21/22] [None] attached joint:[None] body:[body_obj_plate_11]\n",
      "\n",
      "Free joint information. n_free_joint:[2]\n",
      " [0/2] [None] body_name_attached:[body_obj_mug_5]\n",
      " [1/2] [None] body_name_attached:[body_obj_plate_11]\n",
      "\n",
      "Revolute joint information. n_rev_joint:[10]\n",
      " [0/10] [joint1] range:[-6.283]~[6.283]\n",
      " [1/10] [joint2] range:[-6.283]~[6.283]\n",
      " [2/10] [joint3] range:[-6.283]~[6.283]\n",
      " [3/10] [joint4] range:[-6.283]~[6.283]\n",
      " [4/10] [joint5] range:[-6.283]~[6.283]\n",
      " [5/10] [joint6] range:[-6.283]~[6.283]\n",
      " [6/10] [rh_r1] range:[0.000]~[1.100]\n",
      " [7/10] [rh_r2] range:[0.000]~[1.000]\n",
      " [8/10] [rh_l1] range:[0.000]~[1.100]\n",
      " [9/10] [rh_l2] range:[0.000]~[1.000]\n",
      "\n",
      "Prismatic joint information. n_pri_joint:[0]\n",
      "\n",
      "Control information. n_ctrl:[10]\n",
      " [0/10] [actuator_joint1] range:[-6.283]~[6.283] gear:[1.00] type:[JOINT]\n",
      " [1/10] [actuator_joint2] range:[-6.283]~[6.283] gear:[1.00] type:[JOINT]\n",
      " [2/10] [actuator_joint3] range:[-6.283]~[6.283] gear:[1.00] type:[JOINT]\n",
      " [3/10] [actuator_joint4] range:[-6.283]~[6.283] gear:[1.00] type:[JOINT]\n",
      " [4/10] [actuator_joint5] range:[-6.283]~[6.283] gear:[1.00] type:[JOINT]\n",
      " [5/10] [actuator_joint6] range:[-6.283]~[6.283] gear:[1.00] type:[JOINT]\n",
      " [6/10] [actuator_rh_r1] range:[0.000]~[1.100] gear:[1.00] type:[JOINT]\n",
      " [7/10] [actuator_rh_r2] range:[0.000]~[1.000] gear:[1.00] type:[JOINT]\n",
      " [8/10] [actuator_rh_l1] range:[0.000]~[1.100] gear:[1.00] type:[JOINT]\n",
      " [9/10] [actuator_rh_l2] range:[0.000]~[1.000] gear:[1.00] type:[JOINT]\n",
      "\n",
      "Camera information. n_cam:[4]\n",
      " [0/4] [agentview] fov:[60.0]\n",
      " [1/4] [topview] fov:[90.0]\n",
      " [2/4] [sideview] fov:[90.0]\n",
      " [3/4] [egocentric] fov:[90.0]\n",
      "\n",
      "n_sensor:[0]\n",
      "sensor_names:[]\n",
      "n_site:[6]\n",
      "site_names:['bottom_site_mug_5', 'top_site_mug_5', 'horizontal_radius_site_mug_5', 'bottom_site_plate_11', 'top_site_plate_11', 'horizontal_radius_site_plate_11']\n",
      "env:[Tabletop] reset\n",
      "env:[Tabletop] reset\n",
      "env:[Tabletop] initalize viewer\n",
      "DONE INITIALIZATION\n"
     ]
    }
   ],
   "source": [
    "TASK_NAME = 'Put mug cup on the plate' \n",
    "xml_path = './asset/example_scene_y.xml'\n",
    "# Define the environment\n",
    "PnPEnv = SimpleEnv(xml_path, seed = SEED, state_type = 'joint_angle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Dataset Fatures and Create your dataset!\n",
    "The dataset is contained as follows:\n",
    "```\n",
    "fps = 20,\n",
    "features={\n",
    "    \"observation.image\": {\n",
    "        \"dtype\": \"image\",\n",
    "        \"shape\": (256, 256, 3),\n",
    "        \"names\": [\"height\", \"width\", \"channels\"],\n",
    "    },\n",
    "    \"observation.wrist_image\": {\n",
    "        \"dtype\": \"image\",\n",
    "        \"shape\": (256, 256, 3),\n",
    "        \"names\": [\"height\", \"width\", \"channel\"],\n",
    "    },\n",
    "    \"observation.state\": {\n",
    "        \"dtype\": \"float32\",\n",
    "        \"shape\": (6,),\n",
    "        \"names\": [\"state\"], # x, y, z, roll, pitch, yaw\n",
    "    },\n",
    "    \"action\": {\n",
    "        \"dtype\": \"float32\",\n",
    "        \"shape\": (7,),\n",
    "        \"names\": [\"action\"], # 6 joint angles and 1 gripper\n",
    "    },\n",
    "    \"obj_init\": {\n",
    "        \"dtype\": \"float32\",\n",
    "        \"shape\": (6,),\n",
    "        \"names\": [\"obj_init\"], # just the initial position of the object. Not used in training.\n",
    "    },\n",
    "},\n",
    "```\n",
    "\n",
    "\n",
    "This will make the dataset on './demo_data' folder, which will look like this,\n",
    "\n",
    "```\n",
    ".\n",
    "├── data\n",
    "│   ├── chunk-000\n",
    "│   │   ├── episode_000000.parquet\n",
    "│   │   └── ...\n",
    "├── meta\n",
    "│   ├── episodes.jsonl\n",
    "│   ├── info.json\n",
    "│   ├── stats.json\n",
    "│   └── tasks.jsonl\n",
    "└── \n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory ./demo_data already exists.\n",
      "Load from previous dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 116 examples [00:00, 3843.33 examples/s]\n"
     ]
    }
   ],
   "source": [
    "create_new = True\n",
    "if os.path.exists(ROOT):\n",
    "    print(f\"Directory {ROOT} already exists.\")\n",
    "    ans = input(\"Do you want to delete it? (y/n) \")\n",
    "    if ans == 'y':\n",
    "        import shutil\n",
    "        shutil.rmtree(ROOT)\n",
    "    else:\n",
    "        create_new = False\n",
    "\n",
    "\n",
    "if create_new:\n",
    "    dataset = LeRobotDataset.create(\n",
    "                repo_id=REPO_NAME,\n",
    "                root = ROOT, \n",
    "                robot_type=\"omy\",\n",
    "                fps=20, # 20 frames per second\n",
    "                features={\n",
    "                    \"observation.image\": {\n",
    "                        \"dtype\": \"image\",\n",
    "                        \"shape\": (256, 256, 3),\n",
    "                        \"names\": [\"height\", \"width\", \"channels\"],\n",
    "                    },\n",
    "                    \"observation.wrist_image\": {\n",
    "                        \"dtype\": \"image\",\n",
    "                        \"shape\": (256, 256, 3),\n",
    "                        \"names\": [\"height\", \"width\", \"channel\"],\n",
    "                    },\n",
    "                    \"observation.state\": {\n",
    "                        \"dtype\": \"float32\",\n",
    "                        \"shape\": (6,),\n",
    "                        \"names\": [\"state\"], # x, y, z, roll, pitch, yaw\n",
    "                    },\n",
    "                    \"action\": {\n",
    "                        \"dtype\": \"float32\",\n",
    "                        \"shape\": (7,),\n",
    "                        \"names\": [\"action\"], # 6 joint angles and 1 gripper\n",
    "                    },\n",
    "                    \"obj_init\": {\n",
    "                        \"dtype\": \"float32\",\n",
    "                        \"shape\": (6,),\n",
    "                        \"names\": [\"obj_init\"], # just the initial position of the object. Not used in training.\n",
    "                    },\n",
    "                },\n",
    "                image_writer_threads=10,\n",
    "                image_writer_processes=5,\n",
    "        )\n",
    "else:\n",
    "    print(\"Load from previous dataset\")\n",
    "    dataset = LeRobotDataset(REPO_NAME, root=ROOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keyboard Control\n",
    "You can teleop your robot with keyboard and collect dataset\n",
    "```\n",
    "---------     -----------------------\n",
    "   w       ->        backward\n",
    "s  a  d        left   forward   right\n",
    "---------      -----------------------\n",
    "In x, y plane\n",
    "\n",
    "---------\n",
    "R: Moving Up\n",
    "F: Moving Down\n",
    "---------\n",
    "In z axis\n",
    "\n",
    "---------\n",
    "Q: Tilt left\n",
    "E: Tilt right\n",
    "UP: Look Upward\n",
    "Down: Look Donward\n",
    "Right: Turn right\n",
    "Left: Turn left\n",
    "---------\n",
    "For rotation\n",
    "\n",
    "---------\n",
    "SPACEBAR: Toggle Gripper\n",
    "--------\n",
    "\n",
    "---------\n",
    "z: reset\n",
    "--------\n",
    "```\n",
    "Reseting your environment will remove the cache data of the current demonstration and restart collection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's teleop our robot and collect data!\n",
    "\n",
    "**To receive the success signal, you have to release the gripper and move upwards above the mug!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start recording\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 105/105 [00:00<00:00, 1231.32 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 2/2 [00:00<00:00, 111.86ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE INITIALIZATION\n"
     ]
    }
   ],
   "source": [
    "action = np.zeros(7)\n",
    "episode_id = 0\n",
    "record_flag = False # Start recording when the robot starts moving\n",
    "while PnPEnv.env.is_viewer_alive() and episode_id < NUM_DEMO:\n",
    "    PnPEnv.step_env()\n",
    "    if PnPEnv.env.loop_every(HZ=20):\n",
    "        # check if the episode is done\n",
    "        done = PnPEnv.check_success()\n",
    "        if done: \n",
    "            # Save the episode data and reset the environment\n",
    "            dataset.save_episode()\n",
    "            PnPEnv.reset(seed = SEED)\n",
    "            episode_id += 1\n",
    "        # Teleoperate the robot and get delta end-effector pose with gripper\n",
    "        action, reset  = PnPEnv.teleop_robot()\n",
    "        if not record_flag and sum(action) != 0:\n",
    "            record_flag = True\n",
    "            print(\"Start recording\")\n",
    "        if reset:\n",
    "            # Reset the environment and clear the episode buffer\n",
    "            # This can be done by pressing 'z' key\n",
    "            PnPEnv.reset(seed=SEED)\n",
    "            dataset.clear_episode_buffer()\n",
    "            record_flag = False\n",
    "        # Step the environment\n",
    "        joint_q = PnPEnv.step(action)\n",
    "        # Get the end-effector pose and images\n",
    "        ee_pose = PnPEnv.get_ee_pose()\n",
    "        agent_image,wrist_image = PnPEnv.grab_image()\n",
    "        # # resize to 256x256\n",
    "        agent_image = Image.fromarray(agent_image)\n",
    "        wrist_image = Image.fromarray(wrist_image)\n",
    "        agent_image = agent_image.resize((256, 256))\n",
    "        wrist_image = wrist_image.resize((256, 256))\n",
    "        agent_image = np.array(agent_image)\n",
    "        wrist_image = np.array(wrist_image)\n",
    "        if record_flag:\n",
    "            # Add the frame to the dataset\n",
    "            dataset.add_frame( {\n",
    "                    \"observation.image\": agent_image,\n",
    "                    \"observation.wrist_image\": wrist_image,\n",
    "                    \"observation.state\": ee_pose, \n",
    "                    \"action\": joint_q,\n",
    "                    \"obj_init\": PnPEnv.obj_init_pose,\n",
    "                    \"task\": TASK_NAME,\n",
    "                }\n",
    "            )\n",
    "        PnPEnv.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "PnPEnv.env.close_viewer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up the images folder\n",
    "import shutil\n",
    "shutil.rmtree(dataset.root / 'images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lerobot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
